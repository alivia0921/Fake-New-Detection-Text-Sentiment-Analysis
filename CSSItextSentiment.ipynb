{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alivia0921/Fake-New-Detection-Text-Sentiment-Analysis/blob/main/CSSItextSentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataset: https://www.kaggle.com/datasets/jruvika/fake-news-detection"
      ],
      "metadata": {
        "id": "RdDpDaLi0vQg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jc8_xZsZPARx",
        "outputId": "6689dc6a-06a7-443d-9fd3-4b230b66b2ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ],
      "source": [
        "#importing necesary libraries\n",
        "import nltk\n",
        "import spacy\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn import metrics\n",
        "from matplotlib import pyplot\n",
        "import itertools\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from keras.layers import Dense,Embedding,LSTM,Dropout\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import LSTM, Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing dataset\n",
        "dpath = \"/content/data.csv\"\n",
        "df = pd.read_csv(dpath)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "rNNWUwS6PD_4",
        "outputId": "c2fa572a-3e6d-438e-dd67-5f165c8cf8bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6c0693370da3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#importing dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/data.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "zWUAi66hPUeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "bG3H-0lxPYFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "hFvoBEcnPa9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "H655lvJ4PfRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combining the headline and body into one column\n",
        "df['Body'] = df['Body'].fillna(' ')\n",
        "df['CompleteNews'] = df['Headline'] + \" \" + df['Body']\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "9K51osKDP-32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Label'].value_counts()"
      ],
      "metadata": {
        "id": "wwP1rNK7Pkm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Kv2OYbjxSe5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping old columns\n",
        "df = df.drop([\"URLs\", \"Headline\", \"Body\"], axis = 1)"
      ],
      "metadata": {
        "id": "PLtxcyhDRqkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "pWhq69WHSzlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking to see if the data is balanced\n",
        "sns.countplot(df['Label'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vXJHu8joS1Rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing words that have little to no significance in the meaning of phrases - such as 'the', 'of', etc.\n",
        "nltk.download('stopwords')\n",
        "stop_word = set(stopwords.words('english'))\n",
        "print(stop_word)"
      ],
      "metadata": {
        "id": "rqasUSfCS-kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#only taking the alphabet, not punction, and converts it to lowercase\n",
        "ps = PorterStemmer()\n",
        "def textProcess (news):\n",
        "  news = news.lower()\n",
        "  news = re.sub('[^a-zA-Z]',' ', news)  #only take alphabets\n",
        "  news = news.split()\n",
        "  helper = []\n",
        "  for i in news:\n",
        "    if i in stop_word:\n",
        "      pass\n",
        "    else:\n",
        "      helper.append(ps.stem(i))\n",
        "\n",
        "  news = ' '.join(helper)\n",
        "  return news\n",
        "\n"
      ],
      "metadata": {
        "id": "1-QHJLwOTsss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textProcess(df['CompleteNews'][0])\n",
        "# test the preprocessing method"
      ],
      "metadata": {
        "id": "_5dwrVvNVp4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now saving completed news at the processed text\n",
        "newsProcessed = [textProcess(i) for i in tqdm(df['CompleteNews'])]\n",
        "df['CompleteNews'] = newsProcessed\n",
        "df.head()"
      ],
      "metadata": {
        "id": "BkxO8Wm8XAyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the real news in a seperate list\n",
        "dfTrue = df[df['Label']==1].reset_index()\n",
        "TrueNews = []\n",
        "for i in range(1872):\n",
        "  TrueNews.append(dfTrue['CompleteNews'][i])\n",
        "\n",
        "TrueNews = ' '.join(TrueNews) #join the array\n"
      ],
      "metadata": {
        "id": "qhLznsH2eRWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the fake news in a seperate list\n",
        "dfFake = df[df['Label']==0].reset_index()\n",
        "FakeNews = []\n",
        "for i in range(2137):\n",
        "  FakeNews.append(dfFake['CompleteNews'][i])\n",
        "\n",
        "FakeNews = ' '.join(FakeNews) #join the array"
      ],
      "metadata": {
        "id": "L3VGDk58e1lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a wordcloud for real news\n",
        "wordcloud = WordCloud(collocations = False,\n",
        "                background_color ='white',\n",
        "                min_font_size = 10).generate(TrueNews)\n",
        "\n",
        "# plot the WordCloud image\n",
        "plt.figure(figsize = (8, 8), facecolor = None)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1T2XRMMAjSSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a wordcloud for fake news\n",
        "wordcloud = WordCloud(collocations = False,\n",
        "                background_color ='white',\n",
        "                min_font_size = 10).generate(FakeNews)\n",
        "\n",
        "# plot the WordCloud image\n",
        "plt.figure(figsize = (8, 8), facecolor = None)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VHa3OQVxuEFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Bag of Words"
      ],
      "metadata": {
        "id": "xyhHBWwSu7qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creates a vector based on the frequency of each word in the text\n",
        "# processedNewsInput = CountVectorizer(ngram_range=(1,2), max_df=0.9, min_df=3, max_features=2400).fit_transform(newsProcessed).toarray()"
      ],
      "metadata": {
        "id": "nveF5pYVfDCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processedNewsInput = CountVectorizer(ngram_range=(1,2), max_df=0.9, min_df=3, max_features=2400).fit_transform(newsProcessed).toarray()\n"
      ],
      "metadata": {
        "id": "vQTUst-gzOi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = df['Label']"
      ],
      "metadata": {
        "id": "LKq_fXpOfndu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(processedNewsInput, target, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "sIox9iRwfsy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_4_metrics(target_test, predicted):\n",
        "  print(\"%-12s %f\" % ('Accuracy:', metrics.accuracy_score(target_test,predicted)))\n",
        "  print(\"%-12s %f\" % ('Precision:', metrics.precision_score(target_test, predicted,labels=None, pos_label=1, average='binary', sample_weight=None)))\n",
        "  print(\"%-12s %f\" % ('Recall:', metrics.recall_score(target_test, predicted,labels=None, pos_label=1, average='binary', sample_weight=None)))\n",
        "  print(\"%-12s %f\" % ('F1 Score:', metrics.f1_score(target_test, predicted,labels=None, pos_label=1, average='binary', sample_weight=None)))"
      ],
      "metadata": {
        "id": "o-1PANgZjg4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function that allows you to draw nicely formatted confusion matrices\n",
        "def draw_confusion_matrix(y, yhat, classes):\n",
        "    '''\n",
        "        Draws a confusion matrix for the given target and predictions\n",
        "        Adapted from scikit-learn and discussion example.\n",
        "    '''\n",
        "    plt.cla()\n",
        "    plt.clf()\n",
        "    matrix = confusion_matrix(y, yhat)\n",
        "    plt.imshow(matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.colorbar()\n",
        "    num_classes = len(classes)\n",
        "    plt.xticks(np.arange(num_classes), classes, rotation=90)\n",
        "    plt.yticks(np.arange(num_classes), classes)\n",
        "\n",
        "    fmt = 'd'\n",
        "    thresh = matrix.max() / 2.\n",
        "    for i, j in itertools.product(range(matrix.shape[0]), range(matrix.shape[1])):\n",
        "        plt.text(j, i, format(matrix[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if matrix[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "udIg-2lznKal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accList = []\n",
        "precisionList = []\n",
        "recallList = []\n",
        "F1List = []"
      ],
      "metadata": {
        "id": "BlNi3ePTmPdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression, l1 regularization"
      ],
      "metadata": {
        "id": "r3cvex17n72X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#prepares and fits a logistic regression model using L1 regularization\n",
        "log_reg = LogisticRegression(penalty = 'l1', solver = 'liblinear')\n",
        "log_reg.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "Vadw7syNfz9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_predicted = log_reg.predict(x_test)\n",
        "log_score = log_reg.predict_proba(x_test)[:, 1]\n",
        "\n",
        "print_4_metrics(y_test, log_predicted)\n",
        "\n",
        "fpr_log_reg, tpr_log_reg, thresholds = metrics.roc_curve(y_test,log_score)\n",
        "print(\"Logistic Model Performance Results:\\n\")\n",
        "pyplot.figure(1)\n",
        "pyplot.plot(fpr_log_reg, tpr_log_reg, color='orange', lw=1)\n",
        "pyplot.title(\"ROC curve with Logistic Regression\")\n",
        "pyplot.xlabel('FPR')\n",
        "pyplot.ylabel('TPR')\n",
        "\n",
        "aucroc = metrics.auc(fpr_log_reg, tpr_log_reg)\n",
        "print('AUC of ROC: ', aucroc)\n",
        "\n",
        "accList.append (metrics.accuracy_score(y_test, log_predicted))\n",
        "precisionList.append (metrics.precision_score(y_test, log_predicted))\n",
        "recallList.append(metrics.recall_score(y_test, log_predicted))\n",
        "F1List.append(metrics.f1_score(y_test, log_predicted))"
      ],
      "metadata": {
        "id": "EIoJxfOxkiZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_confusion_matrix(log_predicted, y_test, ['Fake', 'True'])"
      ],
      "metadata": {
        "id": "m_ytXWASn3uI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#runs svm\n",
        "svm = SVC(probability = True)\n",
        "\n",
        "svm.fit(x_train, y_train)\n",
        "\n",
        "predicted = svm.predict(x_test)\n",
        "\n",
        "SVM_score = svm.predict_proba(x_test)[:,1]\n",
        "\n",
        "accList.append (metrics.accuracy_score(y_test, predicted))\n",
        "precisionList.append (metrics.precision_score(y_test, predicted))\n",
        "recallList.append(metrics.recall_score(y_test, predicted))\n",
        "F1List.append(metrics.f1_score(y_test, predicted))"
      ],
      "metadata": {
        "id": "LaXv_i8poAv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#runs decision tree\n",
        "DTC = DecisionTreeClassifier()\n",
        "DTC.fit(x_train, y_train)\n",
        "predicted = DTC.predict(x_test)\n",
        "accList.append (metrics.accuracy_score(y_test, predicted))\n",
        "precisionList.append (metrics.precision_score(y_test, predicted))\n",
        "recallList.append(metrics.recall_score(y_test, predicted))\n",
        "F1List.append(metrics.f1_score(y_test, predicted))"
      ],
      "metadata": {
        "id": "MAlcn82bocVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#runs random forest\n",
        "RF = RandomForestClassifier()\n",
        "RF.fit(x_train, y_train)\n",
        "predicted = RF.predict(x_test)\n",
        "accList.append (metrics.accuracy_score(y_test, predicted))\n",
        "precisionList.append (metrics.precision_score(y_test, predicted))\n",
        "recallList.append(metrics.recall_score(y_test, predicted))\n",
        "F1List.append(metrics.f1_score(y_test, predicted))"
      ],
      "metadata": {
        "id": "fQIsCmCgo2jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#runs multinomial naive bayes\n",
        "MNB = MultinomialNB()\n",
        "MNB.fit(x_train, y_train)\n",
        "predicted = MNB.predict(x_test)\n",
        "accList.append (metrics.accuracy_score(y_test, predicted))\n",
        "precisionList.append (metrics.precision_score(y_test, predicted))\n",
        "recallList.append(metrics.recall_score(y_test, predicted))\n",
        "F1List.append(metrics.f1_score(y_test, predicted))"
      ],
      "metadata": {
        "id": "A8F6cKF-pEaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#finding the best value for k\n",
        "k_values = [1,2,3,5,7,9,10,20,200]\n",
        "\n",
        "for k in k_values:\n",
        "    # run knn here:\n",
        "    # note: when create KNN object, assign parameter \"n_neighbors\" to k\n",
        "    # referece: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
        "    '''your code goes below here'''\n",
        "    knnClassifier = KNeighborsClassifier(n_neighbors=k)\n",
        "    knnClassifier.fit(x_train, y_train)\n",
        "    predicted = knnClassifier.predict(x_test)\n",
        "\n",
        "    # report the accuracy here:\n",
        "    # note: print out k value and use metrics.accuracy_score() do show accuracy\n",
        "    '''your code goes below here'''\n",
        "    print(\"k value: \", k)\n",
        "    print(\"Accuracy score: \", metrics.accuracy_score(y_test, predicted))\n",
        "\n"
      ],
      "metadata": {
        "id": "KxMXgVUbpaB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#runs kNN\n",
        "knnClassifier = KNeighborsClassifier(n_neighbors=1)\n",
        "knnClassifier.fit(x_train, y_train)\n",
        "predicted = knnClassifier.predict(x_test)\n",
        "accList.append (metrics.accuracy_score(y_test, predicted))\n",
        "precisionList.append (metrics.precision_score(y_test, predicted))\n",
        "recallList.append(metrics.recall_score(y_test, predicted))\n",
        "F1List.append(metrics.f1_score(y_test, predicted))"
      ],
      "metadata": {
        "id": "SeAiHZOVpvbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = ['Logistic Regression','SVM','Decision Tree','Random Forest','Multinomial Naive Bayes', 'KNN']\n"
      ],
      "metadata": {
        "id": "QjVdoQXNgAG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_models_accuracy = pd.DataFrame({'Models':models, 'Accuracy':accList, 'Precision':precisionList, 'Recall': recallList, 'F1': F1List})\n",
        "cv_models_accuracy"
      ],
      "metadata": {
        "id": "HWqofKgvgB2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using TFIDF"
      ],
      "metadata": {
        "id": "s036O4ByvEAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creates an array with the weighted tfidf values for each word instead of the basic one previously used\n",
        "tdv = TfidfVectorizer(ngram_range=(1,2), max_df=0.9, min_df=3, max_features=2400)\n",
        "TFIDFVec = tdv.fit_transform(newsProcessed).toarray()"
      ],
      "metadata": {
        "id": "_7IH5RZlvM_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = df['Label']\n",
        "x_train, x_test, y_train, y_test = train_test_split(TFIDFVec, target, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "LAsMkk4uv-yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accList2= []\n",
        "precisionList2 = []\n",
        "recallList2 = []\n",
        "F1List2 = []"
      ],
      "metadata": {
        "id": "zWLzxRI2wMRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#simply runs all the models again using this new array\n",
        "log_reg = LogisticRegression(penalty = 'l1', solver = 'liblinear')\n",
        "log_reg.fit(x_train, y_train)\n",
        "log_predicted = log_reg.predict(x_test)\n",
        "accList2.append (metrics.accuracy_score(y_test, log_predicted))\n",
        "precisionList2.append (metrics.precision_score(y_test, log_predicted))\n",
        "recallList2.append(metrics.recall_score(y_test, log_predicted))\n",
        "F1List2.append(metrics.f1_score(y_test, log_predicted))"
      ],
      "metadata": {
        "id": "poS-_cMiyaJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(probability = True)\n",
        "\n",
        "svm.fit(x_train, y_train)\n",
        "\n",
        "predicted = svm.predict(x_test)\n",
        "\n",
        "SVM_score = svm.predict_proba(x_test)[:,1]\n",
        "\n",
        "accList2.append (metrics.accuracy_score(y_test, predicted))\n",
        "precisionList2.append (metrics.precision_score(y_test, predicted))\n",
        "recallList2.append(metrics.recall_score(y_test, predicted))\n",
        "F1List2.append(metrics.f1_score(y_test, predicted))"
      ],
      "metadata": {
        "id": "9vrlPqguyaXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fakeDetect(news):\n",
        "  input = [news]\n",
        "  processedNewsInput = tdv.transform(input).toarray()\n",
        "  predicted = svm.predict(processedNewsInput)\n",
        "  if (predicted == [0]):\n",
        "    print(\"Fake news\")\n",
        "  elif (predicted == [1]):\n",
        "    print(\"Real news\")"
      ],
      "metadata": {
        "id": "NeNhZqOh4jRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fakeDetect('the new york times selects gilber cruz as its next books editor')\n",
        "fakeDetect('warning something big is about to happen in amnerica the martial law is coming -- 100% chance it will happen')"
      ],
      "metadata": {
        "id": "H6MRMFKa4kC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DTC = DecisionTreeClassifier()\n",
        "DTC.fit(x_train, y_train)\n",
        "predicted = DTC.predict(x_test)\n",
        "accList2.append (metrics.accuracy_score(y_test, predicted))\n",
        "precisionList2.append (metrics.precision_score(y_test, predicted))\n",
        "recallList2.append(metrics.recall_score(y_test, predicted))\n",
        "F1List2.append(metrics.f1_score(y_test, predicted))\n"
      ],
      "metadata": {
        "id": "m14GR-i3wSCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RF = RandomForestClassifier()\n",
        "RF.fit(x_train, y_train)\n",
        "predicted = RF.predict(x_test)\n",
        "accList2.append (metrics.accuracy_score(y_test, predicted))\n",
        "precisionList2.append (metrics.precision_score(y_test, predicted))\n",
        "recallList2.append(metrics.recall_score(y_test, predicted))\n",
        "F1List2.append(metrics.f1_score(y_test, predicted))"
      ],
      "metadata": {
        "id": "4ypW6MpRy08E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MNB = MultinomialNB()\n",
        "MNB.fit(x_train, y_train)\n",
        "predicted = MNB.predict(x_test)\n",
        "accList2.append (metrics.accuracy_score(y_test, predicted))\n",
        "precisionList2.append (metrics.precision_score(y_test, predicted))\n",
        "recallList2.append(metrics.recall_score(y_test, predicted))\n",
        "F1List2.append(metrics.f1_score(y_test, predicted))"
      ],
      "metadata": {
        "id": "81pDDqaCy9lN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knnClassifier = KNeighborsClassifier(n_neighbors=1)\n",
        "knnClassifier.fit(x_train, y_train)\n",
        "predicted = knnClassifier.predict(x_test)\n",
        "accList2.append (metrics.accuracy_score(y_test, predicted))\n",
        "precisionList2.append (metrics.precision_score(y_test, predicted))\n",
        "recallList2.append(metrics.recall_score(y_test, predicted))\n",
        "F1List2.append(metrics.f1_score(y_test, predicted))"
      ],
      "metadata": {
        "id": "NneMbXjjzC26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = ['Logistic Regression','SVM','Decision Tree','Random Forest','Multinomial Naive Bayes', 'KNN']"
      ],
      "metadata": {
        "id": "U1OtRQDazJbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_models_accuracy2 = pd.DataFrame({'Models':models, 'Accuracy':accList2, 'Precision':precisionList2, 'Recall': recallList2, 'F1': F1List2})\n",
        "cv_models_accuracy2"
      ],
      "metadata": {
        "id": "x3R88omnzNHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using WordToVec"
      ],
      "metadata": {
        "id": "EBG4iyX-Llwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#list of words\n",
        "corpus = [sentence.split() for sentence in newsProcessed]"
      ],
      "metadata": {
        "id": "YD-QnGVseCip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model that converts to vectors\n",
        "WordToVec = gensim.models.Word2Vec(corpus, window=5, min_count=2)"
      ],
      "metadata": {
        "id": "58ihIY4NWPxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AvgWordToVec(text):\n",
        "    return np.mean([WordToVec.wv[i] for i in text if i in WordToVec.wv.vocab], axis = 0)"
      ],
      "metadata": {
        "id": "aeTPUrX1XxBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#actually converting the data to vectors\n",
        "vectorised = []\n",
        "for doc in tqdm(corpus):\n",
        "    vectorised.append(AvgWordToVec(doc))"
      ],
      "metadata": {
        "id": "sJ_5vr3Ta9t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting the vectors into an array\n",
        "word2VecInput = np.array(vectorised)\n",
        "target = df['Label']\n",
        "x_train, x_test, y_train, y_test = train_test_split(word2VecInput, target, random_state=0, test_size=0.3)"
      ],
      "metadata": {
        "id": "c49-WL52gD5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accList3= []\n",
        "precisionList3 = []\n",
        "recallList3 = []\n",
        "F1List3 = []"
      ],
      "metadata": {
        "id": "5UV5tI-lhzxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#once again, just running the same models with this new array\n",
        "log_reg = LogisticRegression(penalty = 'l1', solver = 'liblinear')\n",
        "log_reg.fit(x_train, y_train)\n",
        "log_predicted = log_reg.predict(x_test)\n",
        "accList3.append (metrics.accuracy_score(y_test, log_predicted))\n",
        "precisionList3.append (metrics.precision_score(y_test, log_predicted))\n",
        "recallList3.append(metrics.recall_score(y_test, log_predicted))\n",
        "F1List3.append(metrics.f1_score(y_test, log_predicted))"
      ],
      "metadata": {
        "id": "xSTa6znoh9e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(probability = True)\n",
        "\n",
        "svm.fit(x_train, y_train)\n",
        "\n",
        "predicted = svm.predict(x_test)\n",
        "\n",
        "SVM_score = svm.predict_proba(x_test)[:,1]\n",
        "\n",
        "accList3.append (metrics.accuracy_score(y_test, predicted))\n",
        "precisionList3.append (metrics.precision_score(y_test, predicted))\n",
        "recallList3.append(metrics.recall_score(y_test, predicted))\n",
        "F1List3.append(metrics.f1_score(y_test, predicted))"
      ],
      "metadata": {
        "id": "MeZIippoh-Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DTC = DecisionTreeClassifier()\n",
        "DTC.fit(x_train, y_train)\n",
        "predicted = DTC.predict(x_test)\n",
        "accList3.append (metrics.accuracy_score(y_test, predicted))\n",
        "precisionList3.append (metrics.precision_score(y_test, predicted))\n",
        "recallList3.append(metrics.recall_score(y_test, predicted))\n",
        "F1List3.append(metrics.f1_score(y_test, predicted))"
      ],
      "metadata": {
        "id": "VTObcWwUiGjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RF = RandomForestClassifier()\n",
        "RF.fit(x_train, y_train)\n",
        "predicted = RF.predict(x_test)\n",
        "accList3.append (metrics.accuracy_score(y_test, predicted))\n",
        "precisionList3.append (metrics.precision_score(y_test, predicted))\n",
        "recallList3.append(metrics.recall_score(y_test, predicted))\n",
        "F1List3.append(metrics.f1_score(y_test, predicted))"
      ],
      "metadata": {
        "id": "Egc-eZFhiPJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knnClassifier = KNeighborsClassifier(n_neighbors=1)\n",
        "knnClassifier.fit(x_train, y_train)\n",
        "predicted = knnClassifier.predict(x_test)\n",
        "accList3.append (metrics.accuracy_score(y_test, predicted))\n",
        "precisionList3.append (metrics.precision_score(y_test, predicted))\n",
        "recallList3.append(metrics.recall_score(y_test, predicted))\n",
        "F1List3.append(metrics.f1_score(y_test, predicted))"
      ],
      "metadata": {
        "id": "-GDJqWjEiZ4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = ['Logistic Regression','SVM','Decision Tree','Random Forest', 'KNN']"
      ],
      "metadata": {
        "id": "b_98kN9mifjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_models_accuracy3 = pd.DataFrame({'Models':models, 'Accuracy':accList3, 'Precision':precisionList3, 'Recall': recallList3, 'F1': F1List3})\n",
        "cv_models_accuracy3"
      ],
      "metadata": {
        "id": "oN4kKx7XihD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "xFA3b8ksnrFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def WordToVecCombined(text, length=500):\n",
        "    sent_vec = np.array([WordToVec.wv[i] for i in text if i in WordToVec.wv.vocab])\n",
        "    if(sent_vec.shape[0] > length):\n",
        "      sent_vec = sent_vec[:length]\n",
        "\n",
        "    sent_vec_new = np.zeros((length, sent_vec.shape[1]))\n",
        "    sent_vec_new[:sent_vec.shape[0]] = sent_vec\n",
        "    return sent_vec_new"
      ],
      "metadata": {
        "id": "qJ2JhTQOxmn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "corpus_new = np.array([WordToVecCombined(sent) for sent in tqdm(corpus)])"
      ],
      "metadata": {
        "id": "qHPMejYF1ePx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_new[0]"
      ],
      "metadata": {
        "id": "I0mhYDvd2D6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creates an rNN using LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "98xmFk1Knu2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(corpus_new)"
      ],
      "metadata": {
        "id": "87WEHEQU1X5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = df['Label']\n",
        "x_train, x_test, y_train, y_test = train_test_split(corpus_new, target, random_state=0, test_size=0.3)"
      ],
      "metadata": {
        "id": "yTO9WQoY3iCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trains and goes through the model 10 times\n",
        "history = model.fit(x_train,y_train,epochs = 10)"
      ],
      "metadata": {
        "id": "ZWWHcBrWp6yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_prob = model(x_test)\n",
        "pred = np.where(pred_prob>=0.5, 1, 0)"
      ],
      "metadata": {
        "id": "YpwFaILI6b2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#uses a confusion matrix to represent the predictions\n",
        "cm = confusion_matrix(y_test, pred)\n",
        "plt.figure(figsize=(5,5))\n",
        "sns.heatmap(cm, annot=True, fmt='', cbar=False, linewidths=2,\n",
        "            xticklabels = ['Fake','Real'], yticklabels = ['Fake','Real'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted', color='black', fontsize=15)\n",
        "plt.ylabel('Actual', color='black', fontsize=15);"
      ],
      "metadata": {
        "id": "mAvZnkR3tveY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#uses one hot encoding for all the words\n",
        "oneHotEncoded = [one_hot(words, 5000) for words in df['CompleteNews']]"
      ],
      "metadata": {
        "id": "bD7hFCxg7USU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stores the length of words in each news article\n",
        "len_list = []\n",
        "for w in df['CompleteNews']:\n",
        "    w = w.split()\n",
        "    len_list.append(len(w))\n",
        "\n",
        "print('Summary of word length :')\n",
        "pd.Series(len_list).describe()"
      ],
      "metadata": {
        "id": "f6LwOL997vt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# taking sentences length as 400 based on the info above\n",
        "sent_length = 360\n",
        "# cuts the longer ones to 400 and adds more to the ones with less\n",
        "embedded_text = pad_sequences(oneHotEncoded, padding='pre', maxlen=sent_length)\n",
        "embedded_text[:5]"
      ],
      "metadata": {
        "id": "dyg52wE58X_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "practically doing the same thing as done in the previous model\n",
        "this time embeddes the words and converts them at the same time as performing LSTM\n",
        "instead of using word2vec beforehand and feeding those vectors\n",
        "'''\n",
        "model = Sequential()\n",
        "model.add(Embedding(5000, 100, input_length=sent_length))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "oDUUFO4a8l-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the dataset into train and test\n",
        "x_train, x_test, y_train, y_test = train_test_split(np.array(embedded_text), df.Label, test_size=0.3, random_state=3)"
      ],
      "metadata": {
        "id": "zpQlyb4M8wda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.33, random_state=3)"
      ],
      "metadata": {
        "id": "AV69qpQEe7OK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape, x_val.shape, x_train.shape"
      ],
      "metadata": {
        "id": "1R6akj1HfMiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting the model\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=64)"
      ],
      "metadata": {
        "id": "3rkZ3H4u846k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#another confusion matrix except this time it's much more accurate\n",
        "pred_prob = model(x_test)\n",
        "pred = np.where(pred_prob>=0.5, 1, 0)\n",
        "\n",
        "cm = confusion_matrix(y_test, pred)\n",
        "plt.figure(figsize=(5,5))\n",
        "sns.heatmap(cm, annot=True, fmt='', cbar=False, linewidths=2,\n",
        "            xticklabels = ['Fake','Real'], yticklabels = ['Fake','Real'])\n",
        "plt.title('confusion matrix')\n",
        "plt.xlabel('Predicted', color='black', fontsize=15)\n",
        "plt.ylabel('Actual', color='black', fontsize=15);"
      ],
      "metadata": {
        "id": "NKYsrt609FjL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}